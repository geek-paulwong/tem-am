<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>OpenAI WebRTC Voice Agent</title>
  <style>
    /* Mobile-friendly layout */
    body {
      font-family: Arial, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: flex-start;
      min-height: 100vh;
      margin: 0;
      padding: 20px;
      background-color: #f4f4f4;
      color: #333;
    }

    h1 {
      font-size: 1.8rem;
      text-align: center;
      margin-bottom: 30px;
    }

    #startBtn {
      padding: 15px 30px;
      font-size: 1.2rem;
      border: none;
      border-radius: 10px;
      background-color: #007bff;
      color: white;
      cursor: pointer;
      transition: background-color 0.2s;
      margin-bottom: 20px;
    }

    #startBtn:active {
      background-color: #0056b3;
    }

    audio {
      margin-top: 20px;
      width: 100%;
      max-width: 500px;
    }

    @media (max-width: 480px) {
      #startBtn {
        width: 100%;
        font-size: 1.1rem;
      }

      h1 {
        font-size: 1.5rem;
      }
    }
  </style>
</head>
<body>
  <h1>WebRTC Voice Agent</h1>
  <button id="startBtn">Start</button>

  <div id="speakingIndicator" style="
    margin-top: 20px;
    padding: 10px 20px;
    border-radius: 10px;
    background-color: #ccc;
    color: #fff;
    font-weight: bold;
    display: none;
    text-align: center;
    width: 150px;
  ">Speaking...</div>

  <div id="debugPanel" style="
    position: fixed;
    bottom: 10px;
    left: 10px;
    right: 10px;
    max-height: 200px;
    overflow-y: auto;
    background: rgba(0,0,0,0.7);
    color: #fff;
    font-family: monospace;
    font-size: 12px;
    padding: 10px;
    border-radius: 8px;
    z-index: 1000;
  "></div>

  <script>
    function debugLog(...args) {
      console.log(...args);
      const panel = document.getElementById("debugPanel");
      if (panel) {
        const msg = args.map(a => (typeof a === "object" ? JSON.stringify(a) : a)).join(" ");
        const line = document.createElement("div");
        line.textContent = `[DEBUG] ${msg}`;
        panel.appendChild(line);
        panel.scrollTop = panel.scrollHeight;
      }
    }

    async function start() {
      debugLog("Starting WebRTC session...");
      try {
        // 1ï¸âƒ£ Request session from backend (gets client_secret only)
        const session = await fetch("/session-webrtc", { method: "POST" }).then(r => r.json());
        debugLog("Received session from backend:", session);
        if (!session.client_secret?.value) {
          console.error("[ERROR] Missing client_secret in session response:", session);
          return;
        }
        const clientSecret = session.client_secret.value;

        // 2ï¸âƒ£ Create PeerConnection
        const pc = new RTCPeerConnection();
        debugLog("RTCPeerConnection created");

        // 3ï¸âƒ£ Handle AI audio track
        pc.ontrack = event => {
          debugLog("ðŸ”¹ðŸ”¹ðŸ”¹ Received AI audio track");
          const audio = document.createElement("audio");
          audio.srcObject = event.streams[0];
          audio.autoplay = true;
          audio.controls = true;
          document.body.appendChild(audio);
        };

        pc.onconnectionstatechange = () => debugLog("connectionState:", pc.connectionState);
        pc.oniceconnectionstatechange = () => debugLog("iceConnectionState:", pc.iceConnectionState);
        pc.onicecandidate = e => { if (e.candidate) debugLog("New ICE candidate:", e.candidate); };

        // 4ï¸âƒ£ Capture microphone audio
        const mic = await navigator.mediaDevices.getUserMedia({ audio: true });
        mic.getTracks().forEach(track => pc.addTrack(track, mic));
        debugLog("Microphone track added");

        // ðŸ”¹ Show speaking indicator as soon as mic is active
        showSpeakingIndicator();

        // Optional: hide after a while (or when session ends)
        // You could hide it when connectionState becomes "disconnected" or on track end:
        mic.getTracks().forEach(track => {
          track.onended = () => hideSpeakingIndicator();
        });

        // 5ï¸âƒ£ Create local SDP offer
        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        debugLog("Local SDP offer created");

        // 6ï¸âƒ£ Send offer to backend, backend will forward to OpenAI
        await fetch("/start-offer", {
          method: "POST",
          headers: { "Content-Type": "application/sdp" },
          body: offer.sdp
        });

        debugLog("Offer sent to backend, WebRTC session should be live");

      } catch (err) {
        console.error("[ERROR] Failed to start WebRTC session:", err);
      }
    }

    function showSpeakingIndicator() {
      const el = document.getElementById("speakingIndicator");
      if (el) el.style.display = "block";
    }

    function hideSpeakingIndicator() {
      const el = document.getElementById("speakingIndicator");
      if (el) el.style.display = "none";
    }

    // Bind button after DOM is loaded
    document.addEventListener("DOMContentLoaded", () => {
      const startBtn = document.getElementById("startBtn");
      startBtn.onclick = start;
      debugLog("Start button bound to start()");
    });
  </script>
</body>
</html>
